{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3176502c",
   "metadata": {},
   "source": [
    "**NOTE** this notebook is supposed to represent the final work implementation for the model based on the different training experimentations done in the previous notebooks for training and tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a9d9d",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "294e422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c947d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/processed/dfd_cle_RR_viz_pow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd91a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \n",
    "    # iterate through all the columns of a dataframe and modify the data type\n",
    "    #   to reduce memory usage.        \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f649dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 973.25 MB\n",
      "Memory usage after optimization is: 343.99 MB\n",
      "Decreased by 64.7%\n"
     ]
    }
   ],
   "source": [
    "df_optimized = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2070900",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f21a4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('Id' in df_optimized.columns) or ('groupId' in df_optimized.columns) or ('matchId' in df_optimized.columns):\n",
    "        df_optimized = df_optimized.drop(columns=['Id', 'groupId', 'matchId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf73a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(df_optimized[['matchType']])\n",
    "\n",
    "new_arrs = enc.transform(df_optimized[['matchType']]).toarray()\n",
    "new_arrs = pd.DataFrame(data=new_arrs, columns = [f'matchType_dum {i}' for i in range(1, new_arrs.shape[1] + 1)])\n",
    "df_optimized = df_optimized.drop(columns=['matchType'], axis=1)\n",
    "df_optimized = pd.concat([df_optimized, new_arrs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de3f8db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>assists</th>\n",
       "      <td>-0.456787</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>2.183594</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>-0.456787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boosts</th>\n",
       "      <td>-0.841797</td>\n",
       "      <td>-0.841797</td>\n",
       "      <td>-0.841797</td>\n",
       "      <td>-0.841797</td>\n",
       "      <td>-0.841797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damageDealt</th>\n",
       "      <td>-1.394531</td>\n",
       "      <td>0.322510</td>\n",
       "      <td>0.154175</td>\n",
       "      <td>-0.213013</td>\n",
       "      <td>0.375244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBNOs</th>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.765625</td>\n",
       "      <td>-0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headshotKills</th>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.446045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heals</th>\n",
       "      <td>-0.793457</td>\n",
       "      <td>-0.793457</td>\n",
       "      <td>-0.793457</td>\n",
       "      <td>-0.793457</td>\n",
       "      <td>-0.793457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killPlace</th>\n",
       "      <td>0.498047</td>\n",
       "      <td>0.399658</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>-0.008972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killPoints</th>\n",
       "      <td>1.217773</td>\n",
       "      <td>-0.821777</td>\n",
       "      <td>-0.821777</td>\n",
       "      <td>-0.821777</td>\n",
       "      <td>-0.821777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kills</th>\n",
       "      <td>-0.843262</td>\n",
       "      <td>-0.843262</td>\n",
       "      <td>-0.843262</td>\n",
       "      <td>-0.843262</td>\n",
       "      <td>0.805664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killStreaks</th>\n",
       "      <td>-0.855957</td>\n",
       "      <td>-0.855957</td>\n",
       "      <td>-0.855957</td>\n",
       "      <td>-0.855957</td>\n",
       "      <td>1.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longestKill</th>\n",
       "      <td>-0.833008</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>-0.833008</td>\n",
       "      <td>1.392578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchDuration</th>\n",
       "      <td>-1.465820</td>\n",
       "      <td>1.782227</td>\n",
       "      <td>-1.174805</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxPlace</th>\n",
       "      <td>-0.768066</td>\n",
       "      <td>-0.982422</td>\n",
       "      <td>0.632324</td>\n",
       "      <td>-0.488037</td>\n",
       "      <td>1.751953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numGroups</th>\n",
       "      <td>-0.812988</td>\n",
       "      <td>-0.901855</td>\n",
       "      <td>0.471191</td>\n",
       "      <td>-0.492432</td>\n",
       "      <td>1.854492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rankPoints</th>\n",
       "      <td>0.869141</td>\n",
       "      <td>-0.143433</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>-1.333008</td>\n",
       "      <td>-2.240234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revives</th>\n",
       "      <td>-0.387207</td>\n",
       "      <td>-0.387207</td>\n",
       "      <td>-0.387207</td>\n",
       "      <td>-0.387207</td>\n",
       "      <td>-0.387207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rideDistance</th>\n",
       "      <td>-0.570312</td>\n",
       "      <td>-0.564453</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>-0.570312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roadKills</th>\n",
       "      <td>-0.052826</td>\n",
       "      <td>-0.052826</td>\n",
       "      <td>-0.052826</td>\n",
       "      <td>-0.052826</td>\n",
       "      <td>-0.052826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swimDistance</th>\n",
       "      <td>-0.256348</td>\n",
       "      <td>3.916016</td>\n",
       "      <td>-0.256348</td>\n",
       "      <td>-0.256348</td>\n",
       "      <td>-0.256348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teamKills</th>\n",
       "      <td>-0.148193</td>\n",
       "      <td>-0.148193</td>\n",
       "      <td>-0.148193</td>\n",
       "      <td>-0.148193</td>\n",
       "      <td>-0.148193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicleDestroys</th>\n",
       "      <td>-0.084229</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>-0.084229</td>\n",
       "      <td>-0.084229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>walkDistance</th>\n",
       "      <td>-0.583496</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>-0.791992</td>\n",
       "      <td>-0.681152</td>\n",
       "      <td>-1.271484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaponsAcquired</th>\n",
       "      <td>-1.250000</td>\n",
       "      <td>0.696777</td>\n",
       "      <td>-0.626465</td>\n",
       "      <td>-0.120117</td>\n",
       "      <td>-0.626465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winPoints</th>\n",
       "      <td>1.299805</td>\n",
       "      <td>-0.806641</td>\n",
       "      <td>-0.806641</td>\n",
       "      <td>-0.806641</td>\n",
       "      <td>-0.806641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winPlacePerc</th>\n",
       "      <td>0.444336</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.166748</td>\n",
       "      <td>0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 15</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matchType_dum 16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1         2         3         4\n",
       "assists          -0.456787 -0.456787  2.183594 -0.456787 -0.456787\n",
       "boosts           -0.841797 -0.841797 -0.841797 -0.841797 -0.841797\n",
       "damageDealt      -1.394531  0.322510  0.154175 -0.213013  0.375244\n",
       "DBNOs            -0.765625 -0.765625 -0.765625 -0.765625 -0.765625\n",
       "headshotKills    -0.446045 -0.446045 -0.446045 -0.446045 -0.446045\n",
       "heals            -0.793457 -0.793457 -0.793457 -0.793457 -0.793457\n",
       "killPlace         0.498047  0.399658  0.061096  0.970703 -0.008972\n",
       "killPoints        1.217773 -0.821777 -0.821777 -0.821777 -0.821777\n",
       "kills            -0.843262 -0.843262 -0.843262 -0.843262  0.805664\n",
       "killStreaks      -0.855957 -0.855957 -0.855957 -0.855957  1.025391\n",
       "longestKill      -0.833008 -0.833008 -0.833008 -0.833008  1.392578\n",
       "matchDuration    -1.465820  1.782227 -1.174805  0.761719  0.601562\n",
       "maxPlace         -0.768066 -0.982422  0.632324 -0.488037  1.751953\n",
       "numGroups        -0.812988 -0.901855  0.471191 -0.492432  1.854492\n",
       "rankPoints        0.869141 -0.143433 -0.014305 -1.333008 -2.240234\n",
       "revives          -0.387207 -0.387207 -0.387207 -0.387207 -0.387207\n",
       "rideDistance     -0.570312 -0.564453 -0.570312 -0.570312 -0.570312\n",
       "roadKills        -0.052826 -0.052826 -0.052826 -0.052826 -0.052826\n",
       "swimDistance     -0.256348  3.916016 -0.256348 -0.256348 -0.256348\n",
       "teamKills        -0.148193 -0.148193 -0.148193 -0.148193 -0.148193\n",
       "vehicleDestroys  -0.084229 -0.084229 -0.084229 -0.084229 -0.084229\n",
       "walkDistance     -0.583496  0.621582 -0.791992 -0.681152 -1.271484\n",
       "weaponsAcquired  -1.250000  0.696777 -0.626465 -0.120117 -0.626465\n",
       "winPoints         1.299805 -0.806641 -0.806641 -0.806641 -0.806641\n",
       "winPlacePerc      0.444336  0.640137  0.775391  0.166748  0.187500\n",
       "matchType_dum 1   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 2   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 3   0.000000  0.000000  1.000000  0.000000  0.000000\n",
       "matchType_dum 4   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 5   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 6   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 7   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 8   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 9   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 10  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 11  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 12  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 13  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 14  0.000000  0.000000  0.000000  0.000000  1.000000\n",
       "matchType_dum 15  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "matchType_dum 16  1.000000  1.000000  0.000000  1.000000  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_optimized.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524b6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_optimized.drop(['winPlacePerc'], axis=1)\n",
    "y = df_optimized['winPlacePerc']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5944528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4354820, 40), (4354820,), (43989, 40), (43989,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5116f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv = {}\n",
    "acc_cv = {}\n",
    "\n",
    "def rmsle_cv(model, model_name):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    acc = cross_val_score(model, X_train.values, y_train, cv = kf)\n",
    "    rmse_cv[model_name] = rmse.mean()\n",
    "    acc_cv[model_name] = acc.mean()\n",
    "    \n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b411f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a88e95d",
   "metadata": {},
   "source": [
    "#### way 1 of building model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86218b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=None)\n",
    "# X is the feature set and y is the target\n",
    "for train_index, test_index in skf.split(X,y): \n",
    "    print(\"Train:\", train_index, \"Validation:\", val_index) \n",
    "    X_train, X_test = X[train_index], X[val_index] \n",
    "    y_train, y_test = y[train_index], y[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "669ac2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "rmse_cv = {}\n",
    "acc_cv = {}\n",
    "\n",
    "def rmsle_cv(model, model_name):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    acc = cross_val_score(model, X_train.values, y_train, cv = kf)\n",
    "    rmse_cv  = rmse.mean()\n",
    "    acc_cv[  = acc.mean()\n",
    "    \n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9795b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=50,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, silent=True)\n",
    "\n",
    "# experiment 3 hyperparameters\n",
    "# model_lgb = lgb.LGBMRegressor(objective='regression', \n",
    "                              \n",
    "#                               reg_alpha=0.0016643092201414056,\n",
    "#                               reg_lambda=0.17444450082323898, colsample_bytree=0.5,\n",
    "#                               subsample=0.5, learning_rate=0.01, max_depth=20,\n",
    "#                               num_leaves=793, min_child_samples=5, min_data_per_groups=66,\n",
    "                              \n",
    "#                               n_estimators=720,\n",
    "#                               max_bin = 55, bagging_fraction = 0.8,\n",
    "#                               bagging_freq = 5, feature_fraction = 0.2319,\n",
    "#                               feature_fraction_seed=9, bagging_seed=9,\n",
    "#                               min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01b939c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "              feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
       "              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=50,\n",
       "              objective=&#x27;regression&#x27;, silent=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "              feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
       "              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=50,\n",
       "              objective=&#x27;regression&#x27;, silent=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=5, bagging_seed=9,\n",
       "              feature_fraction=0.2319, feature_fraction_seed=9,\n",
       "              learning_rate=0.05, max_bin=55, min_data_in_leaf=6,\n",
       "              min_sum_hessian_in_leaf=11, n_estimators=720, num_leaves=50,\n",
       "              objective='regression', silent=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07956501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model results\n",
      "MSE: 0.00790\n",
      "RMSE: 0.08887\n",
      "MAE: 0.06369\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# manually tuned model results\n",
    "expected = y_test.reset_index(drop=True)\n",
    "predicted = model_lgb.predict(X_test)\n",
    "\n",
    "RMSE = mean_squared_error(expected, predicted, squared=False)\n",
    "MSE = mean_squared_error(expected, predicted)\n",
    "MAE = mean_absolute_error(expected, predicted)\n",
    "\n",
    "print('model results')\n",
    "print(\"MSE: %.5f\" % MSE)\n",
    "print(\"RMSE: %.5f\" % RMSE) \n",
    "print(\"MAE: %.5f\" % MAE) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "149459b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "RMSE (CV): 0.08887\n",
      "ACC (CV): 0.91575\n"
     ]
    }
   ],
   "source": [
    "n_folds = 5\n",
    "kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n",
    "rmse= np.sqrt(-cross_val_score(model_lgb, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "acc = cross_val_score(model_lgb, X_train.values, y_train, cv = kf)\n",
    "rmse_cv  = rmse.mean()\n",
    "acc_cv  = acc.mean()\n",
    "       \n",
    "print(\"RMSE (CV): %.5f\" % rmse_cv) \n",
    "print(\"ACC (CV): %.5f\" % acc_cv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b786fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting cv results\n",
    "\n",
    "trials = np.arange(n_folds) + 1\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.plot(trials, acc)\n",
    "# plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "plt.xlabel('Cross validation trial')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.title(\"Cross validation score\")\n",
    "# plt.legend(['test score', 'train score'], loc='upper left')\n",
    "plt.xticks(trials)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8cb3464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model results\n",
      "MSE: 0.01080\n",
      "RMSE: 0.10392\n",
      "MAE: 0.07649\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# experiment 3 results\n",
    "expected = y_test.reset_index(drop=True)\n",
    "predicted = model_lgb.predict(X_test)\n",
    "\n",
    "RMSE = mean_squared_error(expected, predicted, squared=False)\n",
    "MSE = mean_squared_error(expected, predicted)\n",
    "MAE = mean_absolute_error(expected, predicted)\n",
    "\n",
    "print('model results')\n",
    "print(\"MSE: %.5f\" % MSE)\n",
    "print(\"RMSE: %.5f\" % RMSE) \n",
    "print(\"MAE: %.5f\" % MAE) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2985e95",
   "metadata": {},
   "source": [
    "#### way 2 of building model (provides better results by better training procedure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9681dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual tuning parameters\n",
    "# params = {\n",
    "#     \"objective\": 'regression',\n",
    "#     \"num_leaves\": 50,\n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"n_estimators\": 720,\n",
    "# #     \"max_bin\": 55,\n",
    "#     \"bagging_fraction\":0.8,\n",
    "#     \"bagging_freq\":5,\n",
    "#     \"feature_fraction\":0.2319,\n",
    "#     \"feature_fraction_seed\":9,\n",
    "#     \"bagging_seed\":9,\n",
    "#     \"min_data_in_leaf\":6,\n",
    "#     \"min_sum_hessian_in_leaf\":11,\n",
    "#     \"silent\":True\n",
    "# }\n",
    "\n",
    "\n",
    "# experiment 3 parameters \n",
    "params = {\n",
    "    \"reg_alpha\": 0.0016643092201414056,\n",
    "    \"reg_lambda\": 0.17444450082323898, \n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample': 0.5,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 20,\n",
    "    'num_leaves': 793,\n",
    "     'min_child_samples': 77,\n",
    "    'min_data_per_groups': 93\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "070151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    \"max_bin\": 55\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train, params=dataset_params)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, params=dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f9e452f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 764\n",
      "[LightGBM] [Info] Number of data points in the train set: 4354820, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 0.468943\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's l2: 0.0126245\n",
      "[200]\tvalid_0's l2: 0.0102887\n",
      "[300]\tvalid_0's l2: 0.00936787\n",
      "[400]\tvalid_0's l2: 0.00886551\n",
      "[500]\tvalid_0's l2: 0.00849008\n",
      "[600]\tvalid_0's l2: 0.0081025\n",
      "[700]\tvalid_0's l2: 0.00792823\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[720]\tvalid_0's l2: 0.00789762\n"
     ]
    }
   ],
   "source": [
    "model_1 = lgb.train(params, \n",
    "                    train_set = lgb_train,\n",
    "                    num_boost_round=9400,\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=100, \n",
    "                    valid_sets=lgb_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8d1696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model results\n",
      "MSE: 0.00790\n",
      "RMSE: 0.08887\n",
      "MAE: 0.06369\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# manual-tuned results\n",
    "y_pred = model_1.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**(0.5)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('model results')\n",
    "print(\"MSE: %.5f\" % mse)\n",
    "print(\"RMSE: %.5f\" % rmse) \n",
    "print(\"MAE: %.5f\" % mae) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c4059a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model results\n",
      "MSE: 0.00668\n",
      "RMSE: 0.08174\n",
      "MAE: 0.05829\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# experiment 3 results\n",
    "y_pred = model_1.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**(0.5)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('model results')\n",
    "print(\"MSE: %.5f\" % mse)\n",
    "print(\"RMSE: %.5f\" % rmse) \n",
    "print(\"MAE: %.5f\" % mae) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc99c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 3519047, number of used features: 40\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.468913\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's l2: 0.0253715\n",
      "[200]\tvalid_0's l2: 0.0121496\n",
      "[300]\tvalid_0's l2: 0.00912426\n",
      "[400]\tvalid_0's l2: 0.00813958\n",
      "[500]\tvalid_0's l2: 0.00771145\n",
      "[600]\tvalid_0's l2: 0.00748485\n",
      "[700]\tvalid_0's l2: 0.00732255\n",
      "[800]\tvalid_0's l2: 0.00723546\n",
      "[900]\tvalid_0's l2: 0.00717354\n",
      "[1000]\tvalid_0's l2: 0.00712377\n",
      "[1100]\tvalid_0's l2: 0.00708605\n",
      "[1200]\tvalid_0's l2: 0.00705526\n",
      "[1300]\tvalid_0's l2: 0.00702884\n",
      "[1400]\tvalid_0's l2: 0.00700606\n",
      "[1500]\tvalid_0's l2: 0.00698631\n",
      "[1600]\tvalid_0's l2: 0.00697136\n",
      "[1700]\tvalid_0's l2: 0.00695828\n",
      "[1800]\tvalid_0's l2: 0.00694646\n",
      "[1900]\tvalid_0's l2: 0.0069361\n",
      "[2000]\tvalid_0's l2: 0.00692577\n",
      "[2100]\tvalid_0's l2: 0.00691786\n",
      "[2200]\tvalid_0's l2: 0.00691013\n",
      "[2300]\tvalid_0's l2: 0.00690311\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2400]\tvalid_0's l2: 0.00689687\n",
      "[2500]\tvalid_0's l2: 0.00689113\n",
      "[2600]\tvalid_0's l2: 0.00688611\n",
      "[2700]\tvalid_0's l2: 0.00688037\n",
      "[2800]\tvalid_0's l2: 0.00687607\n",
      "[2900]\tvalid_0's l2: 0.00687191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3000]\tvalid_0's l2: 0.00686742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3100]\tvalid_0's l2: 0.00686379\n",
      "[3200]\tvalid_0's l2: 0.00685967\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3300]\tvalid_0's l2: 0.00685765\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3400]\tvalid_0's l2: 0.00685474\n",
      "[3500]\tvalid_0's l2: 0.00685191\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3600]\tvalid_0's l2: 0.00684833\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3700]\tvalid_0's l2: 0.00684543\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3800]\tvalid_0's l2: 0.00684251\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3900]\tvalid_0's l2: 0.00684095\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4000]\tvalid_0's l2: 0.00683755\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4100]\tvalid_0's l2: 0.0068349\n",
      "[4200]\tvalid_0's l2: 0.00683298\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4300]\tvalid_0's l2: 0.00683024\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4400]\tvalid_0's l2: 0.00682823\n",
      "[4500]\tvalid_0's l2: 0.00682669\n",
      "[4600]\tvalid_0's l2: 0.00682559\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4700]\tvalid_0's l2: 0.00682343\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4800]\tvalid_0's l2: 0.00682113\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4900]\tvalid_0's l2: 0.00681871\n",
      "[5000]\tvalid_0's l2: 0.00681694\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5100]\tvalid_0's l2: 0.00681532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5200]\tvalid_0's l2: 0.00681391\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5300]\tvalid_0's l2: 0.00681297\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5400]\tvalid_0's l2: 0.00681185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5500]\tvalid_0's l2: 0.00681052\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5600]\tvalid_0's l2: 0.0068082\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5700]\tvalid_0's l2: 0.00680645\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5800]\tvalid_0's l2: 0.0068056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5900]\tvalid_0's l2: 0.00680395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6000]\tvalid_0's l2: 0.00680237\n",
      "[6100]\tvalid_0's l2: 0.00680042\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6200]\tvalid_0's l2: 0.00679832\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6300]\tvalid_0's l2: 0.00679696\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6400]\tvalid_0's l2: 0.00679584\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6500]\tvalid_0's l2: 0.00679469\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6600]\tvalid_0's l2: 0.00679355\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6700]\tvalid_0's l2: 0.00679223\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6800]\tvalid_0's l2: 0.00679064\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6900]\tvalid_0's l2: 0.00678896\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7000]\tvalid_0's l2: 0.00678801\n",
      "[7100]\tvalid_0's l2: 0.00678709\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7200]\tvalid_0's l2: 0.00678615\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7300]\tvalid_0's l2: 0.00678457\n",
      "[7400]\tvalid_0's l2: 0.00678325\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7500]\tvalid_0's l2: 0.00678141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7600]\tvalid_0's l2: 0.00677967\n",
      "[7700]\tvalid_0's l2: 0.00677872\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7800]\tvalid_0's l2: 0.00677745\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7900]\tvalid_0's l2: 0.00677615\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8000]\tvalid_0's l2: 0.00677511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8100]\tvalid_0's l2: 0.00677407\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8200]\tvalid_0's l2: 0.00677307\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8300]\tvalid_0's l2: 0.00677182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8400]\tvalid_0's l2: 0.00676987\n",
      "[8500]\tvalid_0's l2: 0.00676861\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8600]\tvalid_0's l2: 0.00676736\n",
      "[8700]\tvalid_0's l2: 0.00676555\n",
      "[8800]\tvalid_0's l2: 0.00676435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8900]\tvalid_0's l2: 0.00676316\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9000]\tvalid_0's l2: 0.00676195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9100]\tvalid_0's l2: 0.00676069\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9200]\tvalid_0's l2: 0.0067599\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9300]\tvalid_0's l2: 0.00675883\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9400]\tvalid_0's l2: 0.00675861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9393]\tvalid_0's l2: 0.00675859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 3519047, number of used features: 40\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.468941\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's l2: 0.0253689\n",
      "[200]\tvalid_0's l2: 0.0121652\n",
      "[300]\tvalid_0's l2: 0.00914083\n",
      "[400]\tvalid_0's l2: 0.00815596\n",
      "[500]\tvalid_0's l2: 0.00772623\n",
      "[600]\tvalid_0's l2: 0.00749854\n",
      "[700]\tvalid_0's l2: 0.00733624\n",
      "[800]\tvalid_0's l2: 0.00724703\n",
      "[900]\tvalid_0's l2: 0.00718464\n",
      "[1000]\tvalid_0's l2: 0.00713301\n",
      "[1100]\tvalid_0's l2: 0.00709397\n",
      "[1200]\tvalid_0's l2: 0.00706262\n",
      "[1300]\tvalid_0's l2: 0.00703619\n",
      "[1400]\tvalid_0's l2: 0.00701289\n",
      "[1500]\tvalid_0's l2: 0.00699419\n",
      "[1600]\tvalid_0's l2: 0.00697821\n",
      "[1700]\tvalid_0's l2: 0.00696379\n",
      "[1800]\tvalid_0's l2: 0.00695218\n",
      "[1900]\tvalid_0's l2: 0.00694198\n",
      "[2000]\tvalid_0's l2: 0.00693207\n",
      "[2100]\tvalid_0's l2: 0.00692411\n",
      "[2200]\tvalid_0's l2: 0.00691572\n",
      "[2300]\tvalid_0's l2: 0.00690885\n",
      "[2400]\tvalid_0's l2: 0.00690272\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2500]\tvalid_0's l2: 0.0068969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2600]\tvalid_0's l2: 0.00689114\n",
      "[2700]\tvalid_0's l2: 0.00688645\n",
      "[2800]\tvalid_0's l2: 0.00688229\n",
      "[2900]\tvalid_0's l2: 0.00687834\n",
      "[3000]\tvalid_0's l2: 0.00687497\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3100]\tvalid_0's l2: 0.00687147\n",
      "[3200]\tvalid_0's l2: 0.00686754\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3300]\tvalid_0's l2: 0.00686493\n",
      "[3400]\tvalid_0's l2: 0.00686189\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3500]\tvalid_0's l2: 0.00685984\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3600]\tvalid_0's l2: 0.0068566\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3700]\tvalid_0's l2: 0.00685359\n",
      "[3800]\tvalid_0's l2: 0.00685098\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3900]\tvalid_0's l2: 0.00684906\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4000]\tvalid_0's l2: 0.00684616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4100]\tvalid_0's l2: 0.00684351\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4200]\tvalid_0's l2: 0.00684133\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4300]\tvalid_0's l2: 0.00683925\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4400]\tvalid_0's l2: 0.006837\n",
      "[4500]\tvalid_0's l2: 0.00683563\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4600]\tvalid_0's l2: 0.00683392\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4700]\tvalid_0's l2: 0.00683185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4800]\tvalid_0's l2: 0.00683036\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4900]\tvalid_0's l2: 0.00682783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5000]\tvalid_0's l2: 0.00682561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5100]\tvalid_0's l2: 0.00682381\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5200]\tvalid_0's l2: 0.00682231\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5300]\tvalid_0's l2: 0.00681971\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5400]\tvalid_0's l2: 0.00681821\n",
      "[5500]\tvalid_0's l2: 0.00681655\n",
      "[5600]\tvalid_0's l2: 0.0068146\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5700]\tvalid_0's l2: 0.00681259\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5800]\tvalid_0's l2: 0.00681128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5900]\tvalid_0's l2: 0.00680976\n",
      "[6000]\tvalid_0's l2: 0.00680742\n",
      "[6100]\tvalid_0's l2: 0.00680577\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6200]\tvalid_0's l2: 0.00680457\n",
      "[6300]\tvalid_0's l2: 0.0068029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6400]\tvalid_0's l2: 0.00680118\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6500]\tvalid_0's l2: 0.00679983\n",
      "[6600]\tvalid_0's l2: 0.00679817\n",
      "[6700]\tvalid_0's l2: 0.00679682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6800]\tvalid_0's l2: 0.00679492\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6900]\tvalid_0's l2: 0.0067929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7000]\tvalid_0's l2: 0.00679051\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7100]\tvalid_0's l2: 0.00678925\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7200]\tvalid_0's l2: 0.00678778\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7300]\tvalid_0's l2: 0.00678603\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7400]\tvalid_0's l2: 0.00678471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7500]\tvalid_0's l2: 0.00678321\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7600]\tvalid_0's l2: 0.00678229\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7700]\tvalid_0's l2: 0.00678089\n",
      "[7800]\tvalid_0's l2: 0.00677965\n",
      "[7900]\tvalid_0's l2: 0.00677839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8000]\tvalid_0's l2: 0.0067768\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8100]\tvalid_0's l2: 0.00677529\n",
      "[8200]\tvalid_0's l2: 0.00677407\n",
      "[8300]\tvalid_0's l2: 0.00677292\n",
      "[8400]\tvalid_0's l2: 0.0067708\n",
      "[8500]\tvalid_0's l2: 0.00676967\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8600]\tvalid_0's l2: 0.00676815\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8700]\tvalid_0's l2: 0.00676681\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8800]\tvalid_0's l2: 0.00676578\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8900]\tvalid_0's l2: 0.00676457\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9000]\tvalid_0's l2: 0.0067628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9100]\tvalid_0's l2: 0.00676133\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9200]\tvalid_0's l2: 0.00675981\n",
      "[9300]\tvalid_0's l2: 0.00675856\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9400]\tvalid_0's l2: 0.00675797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9396]\tvalid_0's l2: 0.00675795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\modaj\\AppData\\Roaming\\Python\\Python38\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 3519047, number of used features: 40\n",
      "[LightGBM] [Warning] Unknown parameter: min_data_per_groups\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.468948\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's l2: 0.0253744\n",
      "[200]\tvalid_0's l2: 0.0121677\n",
      "[300]\tvalid_0's l2: 0.00914378\n",
      "[400]\tvalid_0's l2: 0.00815739\n",
      "[500]\tvalid_0's l2: 0.00772796\n",
      "[600]\tvalid_0's l2: 0.00749994\n",
      "[700]\tvalid_0's l2: 0.00733852\n",
      "[800]\tvalid_0's l2: 0.00724965\n",
      "[900]\tvalid_0's l2: 0.00718868\n",
      "[1000]\tvalid_0's l2: 0.00713857\n",
      "[1100]\tvalid_0's l2: 0.00710086\n",
      "[1200]\tvalid_0's l2: 0.0070696\n",
      "[1300]\tvalid_0's l2: 0.00704399\n",
      "[1400]\tvalid_0's l2: 0.00702168\n",
      "[1500]\tvalid_0's l2: 0.00700263\n",
      "[1600]\tvalid_0's l2: 0.00698796\n",
      "[1700]\tvalid_0's l2: 0.0069741\n",
      "[1800]\tvalid_0's l2: 0.00696205\n",
      "[1900]\tvalid_0's l2: 0.00695169\n",
      "[2000]\tvalid_0's l2: 0.00694144\n",
      "[2100]\tvalid_0's l2: 0.00693454\n",
      "[2200]\tvalid_0's l2: 0.00692654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2300]\tvalid_0's l2: 0.00691977\n",
      "[2400]\tvalid_0's l2: 0.00691446\n",
      "[2500]\tvalid_0's l2: 0.00690936\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2600]\tvalid_0's l2: 0.00690392\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2700]\tvalid_0's l2: 0.00689821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2800]\tvalid_0's l2: 0.00689454\n",
      "[2900]\tvalid_0's l2: 0.00689048\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3000]\tvalid_0's l2: 0.00688663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3100]\tvalid_0's l2: 0.00688353\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3200]\tvalid_0's l2: 0.00687977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3300]\tvalid_0's l2: 0.00687723\n",
      "[3400]\tvalid_0's l2: 0.00687408\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3500]\tvalid_0's l2: 0.0068716\n",
      "[3600]\tvalid_0's l2: 0.00686848\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3700]\tvalid_0's l2: 0.0068659\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3800]\tvalid_0's l2: 0.00686254\n",
      "[3900]\tvalid_0's l2: 0.00685963\n",
      "[4000]\tvalid_0's l2: 0.00685636\n",
      "[4100]\tvalid_0's l2: 0.00685363\n",
      "[4200]\tvalid_0's l2: 0.00685117\n",
      "[4300]\tvalid_0's l2: 0.00684878\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4400]\tvalid_0's l2: 0.00684653\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4500]\tvalid_0's l2: 0.00684471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4600]\tvalid_0's l2: 0.00684277\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4700]\tvalid_0's l2: 0.00684113\n",
      "[4800]\tvalid_0's l2: 0.00683944\n",
      "[4900]\tvalid_0's l2: 0.00683733\n",
      "[5000]\tvalid_0's l2: 0.00683573\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5100]\tvalid_0's l2: 0.00683419\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "folds = np.array_split(df_optimized, k)\n",
    "dataset_params = {\n",
    "    \"max_bin\": 55\n",
    "}\n",
    "\n",
    "MAE_cv_final = {}\n",
    "RMSE_cv_final = {}\n",
    "\n",
    "for i in range(k):\n",
    "    train = folds.copy() #you wanna work on a copy of your array\n",
    "    test = folds[i]\n",
    "    del train[i]\n",
    "    train = pd.concat(train, sort=False)\n",
    "    X_test, y_test = test.drop(['winPlacePerc'], axis=1), test['winPlacePerc'] \n",
    "    X_train, y_train = train.drop(['winPlacePerc'], axis=1), train['winPlacePerc'] \n",
    "    \n",
    "    lgb_train_i = lgb.Dataset(X_train, y_train, params=dataset_params)\n",
    "    lgb_eval_i = lgb.Dataset(X_test, y_test, reference=lgb_train, params=dataset_params)\n",
    "    \n",
    "    # experimentaion 3 hyperparameters (provides better results on way 2)\n",
    "    model_1i = lgb.train(params, \n",
    "                    train_set = lgb_train_i,\n",
    "                    num_boost_round=9400,\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=100, \n",
    "                    valid_sets=lgb_eval_i\n",
    "    )\n",
    "    \n",
    "    y_pred = model_1i.predict(X_test)\n",
    "    rmse = (mean_squared_error(y_test, y_pred))**(0.5)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    MAE_cv_final[f'fold {i + 1}'] = mae\n",
    "    RMSE_cv_final[f'fold {i + 1}'] = rmse\n",
    "    \n",
    "    \n",
    "#     perform(clf, train.copy(), test.copy()) // do the fitting, here you also want to copy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataEngineeringKER",
   "language": "python",
   "name": "dataengineeringker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
